---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.8
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python tags=c("hide")}
import numpy as np
import scipy.stats as st
import matplotlib.pyplot as plt
# %matplotlib inline
plt.rcParams["figure.figsize"] = [12,8]
plt.rcParams["animation.html"] = "jshtml"
```

The wicked stepmother has ordered Cinderella to separate a mixture of different ingredients including _i.a._ lentils and ashes. The actual number of ingredients is unknown to poor Cinderella. Fortunately, Cinderella being good and kind has many friends. One of them working in "Birds inc." company lent her the newest model of "Dove" scanner that can measure the diameter of the particles. Using it Cinderella gathered a list containing the diameter of each particle in the mixture. Knowing that for each kind of particles the diameter distribution is normal, she separated the mixture into different ingredients.


Data gathered by  Cinderella can be found in file "data/mixture.txt"

```{python}
data = np.loadtxt('data/mixture.txt')
```

```{python}
plt.hist(data,bins=32, histtype='step', density=True);
```

<!-- #region tags=["problem"] -->
## Problem
<!-- #endregion -->

<!-- #region tags=["problem"] -->
Please redo her analysis. Estimate the number of ingredients in the mixture. Then classify each particle.
<!-- #endregion -->

```{python}
import pandas as pd
```

```{python tags=c()}
data = pd.DataFrame(data)
data.head()
```

```{python}
from sklearn.model_selection import train_test_split
from sklearn.mixture import GaussianMixture
np.random.seed(42)
```

```{python}
c_train, c_test = train_test_split(data, test_size=0.2)
```

```{python}
from math import fabs
err = 10**-3
best_n_comp_all = {}
scores = []
for n_c in range(2, 14):
    c_gm = GaussianMixture(n_components=n_c, tol=1e-5, n_init=3)
    c_gm.fit(c_train)
    score = -c_gm.score(c_test)
    scores.append((n_c, score))
n_c, score = zip(*scores)
best_score = min(score)
best_n_comp = np.argmin(score) + 2
```

```{python}
print(f"Best log score: {best_score}, best number of components: {best_n_comp}")
```

Real number of components: 5

```{python}
x, y = zip(*scores)
fig, ax = plt.subplots(figsize=(10, 10))
ax.plot(x, y)
```

```{python}
best_c_gm = GaussianMixture(n_components=5, tol=1e-5, n_init=3)
best_c_gm.fit(c_train)
```

```{python}
-best_c_gm.score(c_train)
```

```{python}
-best_c_gm.score(c_test)
```

### Bonus question

<!-- #region tags=["problem"] -->
Not knowing the real labels, how can you estimate  the accuracy of this classifier ? 
<!-- #endregion -->

```{python}
labels = []
labels = best_c_gm.predict(data)
```

```{python}
dataset = pd.concat([data.assign(lable=i) for i in labels], ignore_index=True)
```

```{python}
dataset.head()
```
